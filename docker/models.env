# Model Configuration
# Set MODEL_NAME to select which model to use

# Available models:
# - qwen3-vl-30b
# - qwen3-vl-32b-thinking

# Select the model to use (default: qwen3-vl-30b)
MODEL_NAME=qwen3-vl-30b

# Model configurations
# Each model has specific parameters for vLLM

# Model: QuantTrio/Qwen3-VL-30B-A3B-Instruct-AWQ (qwen3-vl-30b)
QWEN3_VL_30B_MODEL=QuantTrio/Qwen3-VL-30B-A3B-Instruct-AWQ
QWEN3_VL_30B_GPU_MEMORY_UTILIZATION=0.95
QWEN3_VL_30B_MAX_MODEL_LEN=100000
QWEN3_VL_30B_EXTRA_ARGS=

# Model: cpatonn/Qwen3-VL-32B-Thinking-AWQ-4bit (qwen3-vl-32b-thinking)
QWEN3_VL_32B_THINKING_MODEL=cpatonn/Qwen3-VL-32B-Thinking-AWQ-4bit
QWEN3_VL_32B_THINKING_GPU_MEMORY_UTILIZATION=0.95
QWEN3_VL_32B_THINKING_MAX_MODEL_LEN=100000
QWEN3_VL_32B_THINKING_EXTRA_ARGS=
